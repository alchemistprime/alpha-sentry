{
  "master": {
    "tasks": [
      {
        "id": "1",
        "title": "Phase 1 Scaffold: Add Mastra deps, create src/mastra structure, Bun smoke import",
        "description": "Install Mastra packages under Bun, add src/mastra directory scaffolding, and verify Mastra imports cleanly without impacting existing LangChain runtime.",
        "details": "- Create branch `feature/mastra-migration` (per PRD).\n- Install deps with Bun:\n  - `bun add @mastra/core @mastra/memory @mastra/libsql`\n- Immediate Bun import smoke test:\n  - `bun -e \"import { Agent } from '@mastra/core/agent'; import { createTool } from '@mastra/core/tools'; console.log('OK')\"`\n- Create directories/files:\n  - `src/mastra/index.ts`\n  - `src/mastra/agents/dexter.ts`\n  - `src/mastra/tools/index.ts` (empty exports initially)\n- Implement Mastra instance (per PRD):\n  - `src/mastra/index.ts`\n    ```ts\n    import { Mastra } from '@mastra/core';\n    import { dexterAgent } from './agents/dexter.js';\n\n    export const mastra = new Mastra({ agents: { dexterAgent } });\n    ```\n- Implement stub agent:\n  - `src/mastra/agents/dexter.ts`\n    ```ts\n    import { Agent } from '@mastra/core/agent';\n\n    export const dexterAgent = new Agent({\n      id: 'dexter',\n      name: 'Dexter',\n      instructions: 'You are Dexter, a helpful financial research assistant.',\n      model: 'openai/gpt-5.2',\n    });\n    ```\n- Add `src/mastra/smoke-test.ts` to generate a simple response:\n  ```ts\n  import { mastra } from './index.js';\n  const agent = mastra.getAgent('dexterAgent');\n  const response = await agent.generate('What is a P/E ratio?');\n  console.log(response.text);\n  ```\n- Ensure coexistence: do not modify existing `src/agent/*` or LangChain wiring yet.",
        "testStrategy": "- Run Bun import smoke test command; expect `OK`.\n- `bun run src/mastra/smoke-test.ts` prints a non-empty `response.text`.\n- `bun run start` still works (existing LangChain agent unaffected).\n- `bun run typecheck` passes.\n- Validate there are no import collisions by running `bun run typecheck` and ensuring no duplicate type/package conflicts are reported.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-10T23:04:46.936Z"
      },
      {
        "id": "2",
        "title": "Phase 2: Port finance leaf tools to Mastra createTool() (mechanical conversion)",
        "description": "Convert finance leaf tools from LangChain DynamicStructuredTool to Mastra createTool() while preserving API layer, formatting, and prompts unchanged.",
        "details": "- For each finance leaf tool in `src/tools/finance/*.ts`, replace LangChain tool definition with Mastra tool definition:\n  - `name` -> `id`\n  - `schema` -> `inputSchema`\n  - `func` -> `execute`\n  - `new DynamicStructuredTool({ ... })` -> `createTool({ ... })`\n- Preserve the real IP unchanged:\n  - `src/tools/finance/api.ts` (`callApi`, caching, auth) must remain and be called identically.\n  - `src/tools/types.ts` (`formatToolResult`, `parseSearchResults`) must remain and be used.\n  - Domain prompting remains unchanged (do not alter prompt content here).\n- Port tools in PRD order (ensure IDs match existing tool names):\n  - Prices: `get_price_snapshot`, `get_prices`\n  - Fundamentals: `get_income_statements`, `get_balance_sheets`, `get_cash_flow_statements`, `get_all_financial_statements`\n  - Key ratios: `get_key_ratios_snapshot`, `get_key_ratios`\n  - Filings leaf: `get_filings`, `get_10K_filing_items`, `get_10Q_filing_items`, `get_8K_filing_items`\n  - Other: `get_analyst_estimates`, `get_segmented_revenues`, `get_insider_trades`, `get_company_facts`\n  - Crypto: `get_crypto_price_snapshot`, `get_crypto_prices`, `get_crypto_tickers`\n  - News: `get_news`\n- Ensure each tool keeps the same output shape as before (usually `formatToolResult(data, [url])`).\n- Note on progress: remove dependency on `config.metadata.onProgress` from these tool implementations; accept `(input, context)` signature but no progress emission yet.\n\nPseudo-code template for each tool:\n```ts\nimport { createTool } from '@mastra/core/tools';\nimport { z } from 'zod';\nimport { callApi } from './api.js';\nimport { formatToolResult } from '../types.js';\n\nexport const someTool = createTool({\n  id: 'tool_id',\n  description: '...',\n  inputSchema: z.object({ /* existing schema */ }),\n  execute: async (input, context) => {\n    // context.abortSignal may be used if supported by callApi\n    const { data, url } = await callApi('/endpoint/', { /* ... */ });\n    return formatToolResult(data?.something ?? {}, [url]);\n  },\n});\n```",
        "testStrategy": "- Add/adjust unit tests per module (or adapt existing) to call `tool.execute()` directly with mocked `callApi`:\n  - Example (pseudo):\n    ```ts\n    vi.mock('./api', () => ({ callApi: vi.fn(async ()=>({data:{...}, url:'u'})) }));\n    const out = await getPriceSnapshot.execute({ ticker:'AAPL' } as any, {} as any);\n    expect(out).toMatchObject({ data: expect.anything(), sourceUrls: ['u'] });\n    ```\n- Run: `bun test src/tools/finance/*.test.ts`.\n- `bun run typecheck`.\n- `bun run start` still works (LangChain agent path still in place until Phase 3/5).",
        "priority": "high",
        "dependencies": [
          "1"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-11T00:28:07.168Z"
      },
      {
        "id": "3",
        "title": "Phase 2: Port non-finance leaf tools (search, browser, skill) to createTool()",
        "description": "Convert Exa/Tavily web_search variants, browser tool, and skill tool to Mastra createTool() while preserving behavior and output formatting contracts.",
        "details": "- Port the following tools to `createTool()`:\n  - `web_search` (Exa variant) in `src/tools/search/`\n  - `web_search` (Tavily variant) in `src/tools/search/`\n  - `browser` in `src/tools/browser/`\n  - `skill` in `src/tools/skill.ts`\n- Ensure tool IDs remain stable (`id: 'web_search'` etc.). If there are two variants, keep unique IDs (or keep existing runtime selection mechanism) consistent with current code; do not change user-facing tool naming without PRD direction.\n- Keep `src/skills/` system intact; skill tool should still load SKILL.md workflows as before.\n- Keep output formatting compatible with existing UI expectations (`formatToolResult` / `parseSearchResults` usage where applicable).\n\nImplementation notes:\n- For tools that previously relied on LangChain callback manager / metadata for progress, accept `(input, context)` but do not implement progress emission yet.\n- Ensure network calls can be aborted if `context.abortSignal` is available; thread abort signal down where possible.\n\nPseudo-code (pattern):\n```ts\nexport const webSearch = createTool({\n  id: 'web_search',\n  description: '...',\n  inputSchema: z.object({ query: z.string(), /* ... */ }),\n  execute: async (input, context) => {\n    // call provider SDK\n    // return parseSearchResults(...) or formatToolResult(...)\n  },\n});\n```",
        "testStrategy": "- Unit tests for each tool calling `.execute()` with mocked provider clients.\n- Validate schemas compile and tool exports are typed.\n- `bun run typecheck`.\n- Smoke test by running a minimal Mastra agent (from Phase 1) with one of these tools temporarily registered locally (or in a small test agent) and verifying it can call `web_search`/`browser` and return formatted results.",
        "priority": "high",
        "dependencies": [
          "1"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-11T00:45:10.748Z"
      },
      {
        "id": "4",
        "title": "Phase 2: Create Mastra tool registry (src/mastra/tools/index.ts) for all ported leaf tools",
        "description": "Create a Mastra-compatible tool registry that re-exports the ported tools without touching the existing LangChain registry yet.",
        "details": "- Implement `src/mastra/tools/index.ts` as the new tool registry used by the Mastra agent.\n- Import tools from existing locations (`src/tools/finance/*`, `src/tools/search/*`, `src/tools/browser/*`, `src/tools/skill.ts`) and export grouped registries:\n  - `financeLeafTools` (all finance leaf tools)\n  - `allLeafTools` (finance + non-finance leaf)\n- Keep this file side-by-side with existing registry. Do not delete old registry until Phase 5.\n\nExample skeleton:\n```ts\n// src/mastra/tools/index.ts\nimport { getPriceSnapshot, getPrices } from '../../tools/finance/prices.js';\n// ... all other leaf tool imports\nimport { webSearch as webSearchExa } from '../../tools/search/exa.js';\nimport { webSearch as webSearchTavily } from '../../tools/search/tavily.js';\nimport { browser } from '../../tools/browser/index.js';\nimport { skill } from '../../tools/skill.js';\n\nexport const financeLeafTools = {\n  getPriceSnapshot,\n  getPrices,\n  // ...\n};\n\nexport const allLeafTools = {\n  ...financeLeafTools,\n  // decide how to expose search variants (keep existing selection behavior)\n  browser,\n  skill,\n};\n```\n- If the current code switches between Exa/Tavily at runtime, implement a thin wrapper tool with stable id that dispatches to the configured variant (do not implement meta-tool routing here; keep simple config-based dispatch).",
        "testStrategy": "- `bun run typecheck` ensures the registry exports a valid object map.\n- Add a small test that iterates over `Object.values(allLeafTools)` and asserts each has expected shape: `{ id, execute, inputSchema }`.\n- Ensure no runtime import errors under Bun by running `bun -e \"import('./src/mastra/tools/index.ts').then(m=>console.log(Object.keys(m.allLeafTools).length))\"`.",
        "priority": "high",
        "dependencies": [
          "2",
          "3"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-11T01:06:01.620Z"
      },
      {
        "id": "5",
        "title": "Phase 3: Implement meta-tools financial_search and read_filings using sub-agents wrapped as Mastra tools",
        "description": "Port LangChain meta-tools to Mastra by creating createTool() wrappers that internally run sub-agents using the leaf tool registry, preserving existing output contracts and prompt policies.",
        "details": "- Implement `src/mastra/tools/financial-search.ts` as per PRD:\n  - Create a `financialRouter` sub-agent with:\n    - `id: 'financial-router'`\n    - `instructions: buildRouterPrompt()` (reuse existing router prompt content)\n    - `model: 'openai/gpt-5.2'`\n    - `tools: financeLeafTools` (registered directly)\n  - Wrap in `createTool({ id: 'financial_search', ... })`.\n  - In `execute`, call `financialRouter.generate(input.query, { maxSteps: 3 })`.\n  - Implement `combineFinancialResults(result.steps)` to aggregate tool outputs into the same `{ data, sourceUrls }` contract expected by the system prompt and UI.\n\n- Implement `src/mastra/tools/read-filings.ts` as per PRD:\n  - Two-step sub-agent workflow:\n    1) identify/select filing metadata (likely calls `get_filings`)\n    2) retrieve and extract requested filing items (calls `get_10K_filing_items` / `get_10Q_filing_items` / `get_8K_filing_items`)\n  - Wrap as `createTool({ id: 'read_filings', ... })`.\n  - Ensure it respects the existing two-step behavior and returns formatted results.\n\n- Update `src/mastra/tools/index.ts` to export these meta-tools and create `allTools`:\n  - `allTools = { ...allLeafTools, financialSearch, readFilings }`\n\nPseudo-code for aggregation:\n```ts\nfunction combineFinancialResults(steps){\n  const data = [];\n  const sourceUrls = new Set();\n  for (const s of steps){\n    if (s.toolResult?.data) data.push(s.toolResult.data);\n    for (const u of (s.toolResult?.sourceUrls ?? [])) sourceUrls.add(u);\n  }\n  return { data, sourceUrls: [...sourceUrls] };\n}\n```\n(Adjust to match the exact output shape used in `formatToolResult`.)",
        "testStrategy": "- Unit tests with mocked sub-agent behavior (or integration tests with mocked leaf tools):\n  - Stub `financeLeafTools` tools to return deterministic results and verify aggregation merges `sourceUrls` and preserves `data` shape.\n- Integration smoke test:\n  - Create a small script to call `financial_search.execute({query:'AAPL PE ratio'})` and assert it returns structured output.\n- Ensure `read_filings` executes two-step flow by asserting it calls expected underlying tools in order (via spies/mocks).",
        "priority": "high",
        "dependencies": [
          "4"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-11T01:21:21.457Z"
      },
      {
        "id": "6",
        "title": "Phase 3: Wire full system prompt + tools into Mastra Dexter agent; replace custom agent loop usage in runner hook",
        "description": "Update Mastra Dexter agent to use existing buildSystemPrompt(), register all tools, and switch the app runner to Mastra agent streaming with maxSteps.",
        "details": "- Update `src/mastra/agents/dexter.ts`:\n  - Use existing prompt builder `buildSystemPrompt()` from `src/agent/prompts.js`.\n  - Register `allTools` from `src/mastra/tools/index.ts`.\n  - Set `model: 'openai/gpt-5.2'`.\n  - Use Mastra `maxSteps` instead of custom while/iteration loop when running.\n\nExample:\n```ts\nimport { Agent } from '@mastra/core/agent';\nimport { buildSystemPrompt } from '../../agent/prompts.js';\nimport { allTools } from '../tools/index.js';\n\nexport const dexterAgent = new Agent({\n  id: 'dexter',\n  name: 'Dexter',\n  instructions: buildSystemPrompt('openai/gpt-5.2'),\n  model: 'openai/gpt-5.2',\n  tools: allTools,\n});\n```\n\n- Update `src/hooks/use-agent-runner.ts` to use:\n  - `const agent = mastra.getAgent('dexterAgent')`\n  - `const stream = await agent.stream(query, { maxSteps: 10 })`\n  - Consume via event bridge generator (implemented in Task 7).\n\nPseudo-code runner change:\n```ts\nconst agent = mastra.getAgent('dexterAgent');\nconst stream = await agent.stream(query, { maxSteps: 10, signal });\nfor await (const evt of bridgeEvents(stream)) {\n  dispatch(evt);\n}\n```",
        "testStrategy": "- Run `bun run src/mastra/smoke-test.ts \"What is Apple's current stock price?\"` and confirm tool usage (may require observing step events/logging).\n- Run CLI `bun run start` and execute a financial query; confirm it completes and produces an answer.\n- `bun run typecheck` passes.\n- Verify maxSteps prevents infinite loops by crafting a prompt that would previously loop; ensure it stops after configured steps.",
        "priority": "high",
        "dependencies": [
          "1",
          "5"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-11T01:42:18.164Z"
      },
      {
        "id": "7",
        "title": "Phase 3: Implement Mastra→AgentEvent event bridge for CLI/Web parity + add JSONL audit log (scratchpad as audit trail)",
        "description": "Create an event bridge mapping Mastra streaming events to existing AgentEvent types and implement append-only JSONL audit logging of tool calls/results.",
        "details": "- Implement `src/mastra/event-bridge.ts` exporting `bridgeEvents(...)` that yields existing `AgentEvent` from `src/agent/types.js`.\n- Mapping requirements (PRD): Ink CLI/web currently expect events like `tool_start`, `tool_end`, `thinking`, `answer_start`, `done`.\n- Use Mastra `agent.stream()` hooks/callbacks:\n  - Use `onStepFinish` (passed in stream options) to detect tool calls/results and emit:\n    - `tool_start` when a tool call is detected (if Mastra provides pre-call hook, otherwise emit start when call appears and end when result is present).\n    - `tool_end` when result is available.\n  - For text streaming, forward incremental tokens/chunks as existing text/answer events (depending on current `AgentEvent` contract).\n\n- Implement `src/mastra/audit-log.ts` JSONL logger:\n  - Append-only file under `.dexter/scratchpad/` (per PRD).\n  - Record `{ ts, thread, tool, args, resultSummary, sourceUrls, toolCallId }`.\n\nPseudo-code audit log:\n```ts\nimport { mkdir, appendFile } from 'node:fs/promises';\nexport async function appendAudit(entry){\n  await mkdir('.dexter/scratchpad', { recursive: true });\n  await appendFile('.dexter/scratchpad/audit.jsonl', JSON.stringify(entry)+'\\n');\n}\n```\n\n- Wire audit log via `onStepFinish` in runner/web route later:\n```ts\nonStepFinish: ({ toolCalls, toolResults }) => {\n  // iterate and appendAudit(...)\n}\n```\n- Maintain scratchpad decision: audit trail only; no context management responsibilities.",
        "testStrategy": "- Unit test `bridgeEvents` with a mocked Mastra stream iterator emitting representative events; assert correct `AgentEvent` outputs.\n- Manual CLI run: confirm tool events appear (start/end) and final answer prints.\n- Verify `.dexter/scratchpad/audit.jsonl` is created and grows with tool calls.\n- Ensure audit logging does not crash if directory missing; test first-run scenario.",
        "priority": "high",
        "dependencies": [
          "6"
        ],
        "status": "in-progress",
        "subtasks": [],
        "updatedAt": "2026-02-11T01:42:32.814Z"
      },
      {
        "id": "8",
        "title": "Phase 3: Update model selection to Mastra model router strings (multi-provider support)",
        "description": "Replace LangChain LLM wrappers with Mastra model router string selection and verify at least OpenAI + one other provider path works, with OpenRouter fallback where needed.",
        "details": "- Update `src/model/llm.ts` behavior to return Mastra model identifiers (or introduce a new module, but PRD later deletes `src/model/llm.ts`; for now implement the needed function and later remove old LangChain code).\n- Implement a function, e.g. `getMastraModelString(provider, model)` that returns strings like:\n  - OpenAI: `'openai/gpt-5.2'`\n  - Anthropic: `'anthropic/claude-sonnet-4'`\n  - Google: `'google/gemini-3-flash-preview'`\n  - Ollama: `'ollama/llama3'`\n  - xAI/Grok/Moonshot/DeepSeek: if not directly supported, use OpenRouter fallback per PRD:\n    - e.g. `'openrouter:xai/grok-4-1-fast-reasoning'`\n- Ensure `dexterAgent` uses the selected model string.\n- If prompt caching is used for Anthropic, pass via `instructions` object with `providerOptions.anthropic.cacheControl.type = 'ephemeral'` as in PRD.\n\nPseudo-code:\n```ts\nexport function getMastraModelString({ provider, model }: {provider:string; model:string}) {\n  if (provider === 'openai') return `openai/${model}`;\n  if (provider === 'anthropic') return `anthropic/${model}`;\n  if (provider === 'google') return `google/${model}`;\n  if (provider === 'ollama') return `ollama/${model}`;\n  if (provider === 'openrouter') return `openrouter:${model}`;\n  return `openai/${model}`; // safe default per current PRD focus\n}\n```",
        "testStrategy": "- Unit test mapping table inputs → expected strings.\n- Manual runtime test:\n  - Configure OpenAI model and run `src/mastra/smoke-test.ts`.\n  - Configure a second provider (e.g., Anthropic) and verify a response is produced.\n- `bun run typecheck` to ensure no LangChain class imports remain in the model selection path used by Mastra agent.",
        "priority": "high",
        "dependencies": [
          "6"
        ],
        "status": "in-progress",
        "subtasks": [],
        "updatedAt": "2026-02-11T01:42:34.851Z"
      },
      {
        "id": "9",
        "title": "Phase 4: Add Mastra Memory (LibSQL store/vector, working memory template, semantic recall) + thread/resource wiring",
        "description": "Implement Mastra Memory with LibSQL-backed persistence, configure message history/working memory/semantic recall, and wire thread/resource IDs for CLI and web sessions.",
        "details": "- Implement LibSQL storage + vector in `src/mastra/index.ts` or `src/mastra/memory.ts` per PRD:\n  - `LibSQLStore({ id, url: 'file:.dexter/memory.db' })`\n  - `LibSQLVector({ id, url: 'file:.dexter/memory.db' })`\n- Implement `src/mastra/memory.ts`:\n  - Create `Memory` instance with:\n    - `embedder: new ModelRouterEmbeddingModel('openai/text-embedding-3-small')`\n    - options:\n      - `lastMessages: 20`\n      - workingMemory enabled with the provided template\n      - semanticRecall: `{ topK: 5, messageRange: 2, scope: 'resource' }`\n- Wire `memory` onto `dexterAgent` in `src/mastra/agents/dexter.ts`.\n- Update runner(s) to pass memory identifiers:\n  - CLI: `thread: cli-${sessionId}`, `resource: 'cli-user'`\n  - Web: `thread: web-${sessionId}`, `resource: user-${sessionId}`\n\nPseudo-code for calling:\n```ts\nawait agent.stream(query, {\n  maxSteps: 10,\n  memory: { thread, resource },\n});\n```\n- Note: PRD indicates existing InMemoryChatHistory/Redis becomes unnecessary after this; do not remove yet until Phase 6 cleanup, but stop relying on it where the Mastra path is used.",
        "testStrategy": "- Run multi-turn smoke test:\n  1) Ask: \"What is AAPL's P/E ratio?\"\n  2) Follow-up: \"How does it compare to MSFT?\"\n  Expect agent to retain AAPL context within same thread.\n- Restart process and ask: \"what were we looking at?\" using same resource; expect working memory/semantic recall to surface prior context.\n- Verify `.dexter/memory.db` is created and non-empty.\n- `bun run typecheck` passes.",
        "priority": "high",
        "dependencies": [
          "6"
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": "10",
        "title": "Phase 5–6: Remove LangChain/LangSmith, finalize Mastra-only path, and implement Vercel AI SDK streaming in Next.js route",
        "description": "Strip LangChain dependencies and dead code, migrate web API chat route to true token streaming via Vercel AI SDK adapter, and remove fake SSE drip + Redis session logic.",
        "details": "Phase 5 (dependency/code removal):\n- Remove deps:\n  - `bun remove @langchain/core @langchain/openai @langchain/anthropic @langchain/google-genai @langchain/ollama @langchain/exa @langchain/tavily langsmith`\n- Delete/replace files as specified:\n  - Delete `src/agent/agent.ts` (custom Agent)\n  - Delete `src/tools/registry.ts` (old registry)\n  - Delete `src/model/llm.ts` (if still present per PRD) and ensure model routing uses Mastra model strings (Task 8)\n  - Keep `src/agent/prompts.ts` and `src/agent/types.ts`\n  - Ensure `src/agent/scratchpad.ts` becomes audit-log-only or is replaced by `src/mastra/audit-log.ts` with no LangChain imports\n- Replace LangSmith tracing with Mastra OpenTelemetry tracing (configure Mastra logger/tracing in `src/mastra/index.ts` per PRD; keep minimal logger configuration).\n\nPhase 6 (web streaming with Vercel AI SDK):\n- In `web/`:\n  - `bun add @mastra/core @mastra/ai-sdk`\n- Replace `web/app/api/chat/route.ts`:\n  - Use Mastra agent stream and `toAISdkV5Stream` adapter:\n    ```ts\n    import { mastra } from '../../../src/mastra/index.js';\n    import { toAISdkV5Stream } from '@mastra/ai-sdk';\n\n    export const runtime = 'nodejs';\n    export const maxDuration = 300;\n\n    export async function POST(req: Request) {\n      const { messages, sessionId } = await req.json();\n      const query = messages[messages.length - 1]?.content;\n      const agent = mastra.getAgent('dexterAgent');\n      const sid = sessionId || crypto.randomUUID();\n\n      const stream = await agent.stream(query, {\n        maxSteps: 5,\n        memory: { thread: `web-${sid}`, resource: `user-${sid}` },\n        onStepFinish: ({ toolCalls, toolResults }) => {\n          // optional: audit log append\n        },\n      });\n\n      const aiStream = toAISdkV5Stream(stream, { from: 'agent' });\n      return new Response(aiStream, {\n        headers: {\n          'Content-Type': 'text/event-stream',\n          'Cache-Control': 'no-cache',\n        },\n      });\n    }\n    ```\n- Update frontend component to use `useChat` from `ai/react`:\n  - Ensure it renders streaming tokens and (optionally) tool event parts.\n- Remove dead code in web route:\n  - delete fake word-by-word delay, SSE encoder helpers, sendEvent/sendText helpers, LangSmith wrappers, and Redis session management.\n\nFinal verification/cleanup:\n- Ensure no `@langchain` imports remain (`grep -r \"@langchain\" src/ web/`).\n- Ensure no `langsmith` imports remain in `web/`.",
        "testStrategy": "Phase 5 tests:\n- `grep -r \"@langchain\" src/ --include=\"*.ts\" --include=\"*.tsx\"` returns zero.\n- `bun run typecheck` passes.\n- `bun test` passes.\n- `bun run start` works end-to-end (CLI) with Mastra.\n\nPhase 6 tests:\n- In `web/`: `bun run build` succeeds; `bun run dev` starts.\n- Browser manual:\n  1) Send \"What is AAPL's P/E ratio?\" and confirm true token streaming (no artificial delays).\n  2) Confirm tool call/result events are visible/handled if UI supports them.\n  3) Send follow-up \"How does it compare to MSFT?\" and confirm memory continuity.\n- Confirm no `langsmith` imports in `web/` via grep.",
        "priority": "high",
        "dependencies": [
          "7",
          "8",
          "9"
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": "11",
        "title": "Add Mastra Evals (scorers) across AlphaSentry agent lifecycle with CI gating and LibSQL trend storage",
        "description": "Install and integrate @mastra/evals, attach live evaluation scorers to the AlphaSentry agent (including a custom financial faithfulness scorer grounded in tool results), configure environment-based sampling, persist results to LibSQL, and add Bun CI eval tests with quality thresholds.",
        "details": "## Scope\nImplement runtime and CI-time evaluation for AlphaSentry using Mastra Evals. This includes built-in scorers (answer relevancy, completeness, toxicity, prompt alignment) plus a custom financial faithfulness scorer that flags hallucinated numbers by verifying the final answer is supported by tool outputs captured during the run.\n\n## Prerequisites/assumptions\n- AlphaSentry is already wired to Mastra tools (tool registry + agent tool wiring) and emits/records tool calls/results (directly or via an event bridge / audit log).\n- Memory is already wired so that eval context can include recent conversation state (where appropriate).\n\n## Dependencies\n- Depends on Phase 3 tool wiring (Task 6) so tool results are available to ground the custom scorer.\n- Depends on Phase 4 memory wiring (Task 9) so scorer context can reference thread/resource history and so storage primitives (LibSQL) are available/consistent.\n\n## Implementation plan\n\n### 1) Install dependency and add wiring points\n- Add dependency:\n  - `bun add @mastra/evals`\n- Create module structure:\n  - `src/mastra/evals/index.ts` – exports scorer factory/wiring helper.\n  - `src/mastra/evals/faithfulness-financial.ts` – custom scorer implementation.\n  - `src/mastra/evals/storage.ts` – LibSQL persistence for eval runs + scores.\n  - `src/mastra/evals/config.ts` – sampling rates and enable/disable flags.\n\n### 2) Define sampling/config policy (dev 100%, prod 10–20%)\nImplement a small config helper that chooses whether to run evals for a given request:\n- Environment-based defaults:\n  - `NODE_ENV !== 'production'`: sample rate = 1.0\n  - `NODE_ENV === 'production'`: sample rate = 0.1 (or configurable up to 0.2)\n- Allow overrides with env vars:\n  - `MASTRA_EVALS_ENABLED=true|false` (default true in dev, true in prod)\n  - `MASTRA_EVALS_SAMPLE_RATE=0..1` (default as above)\n- Deterministic sampling option for stability (recommended): hash of `threadId` or `requestId` to decide inclusion (prevents flapping across requests).\n\n### 3) Attach live scorers to AlphaSentry agent lifecycle\nUpdate the AlphaSentry agent definition (e.g., `src/mastra/agents/alphaSentry.ts` or wherever the agent is defined) to run scorers on completed turns.\n\nImplementation approach (choose one based on Mastra API surface available in this repo):\n- Option A: Use Mastra Evals “live scorers” integration (preferred):\n  - Configure the agent with eval hooks/callbacks that receive:\n    - prompt/system prompt\n    - messages (user + assistant)\n    - tool calls/results (per step)\n    - final assistant output\n- Option B: If agent API doesn’t directly support eval hooks, wrap the runner:\n  - After `agent.stream()` completes, collect:\n    - final text\n    - conversation messages\n    - tool execution transcript (from event bridge/audit log in the same run)\n  - Invoke scorers manually, then persist.\n\nAttach these scorers:\n- `answerRelevancy` (how well the answer matches the user query)\n- `completeness` (coverage of user request)\n- `toxicity` (safety)\n- `promptAlignment` (adherence to system/policy constraints)\n- `financialFaithfulness` (custom)\n\nEnsure scorers run only when sampling allows; otherwise skip with minimal overhead.\n\n### 4) Implement custom financial faithfulness scorer\nGoal: Verify that *numerical claims* in the final answer are grounded in tool results produced during the run (no hallucinated numbers).\n\n#### Inputs required\n- Final assistant answer text.\n- Tool results transcript for that run (preferably structured):\n  - tool name/id\n  - input\n  - output (raw JSON/text)\n  - timestamps\n- Optional: the user question (to focus evaluation).\n\n#### Scoring behavior\nReturn a normalized score (0..1) and reasons.\nRecommended rubric:\n- Extract candidate numeric claims from final answer:\n  - currency amounts, percentages, ratios, prices, market cap, P/E, EPS, revenue, growth rates, dates with numbers, etc.\n  - Use regex + lightweight parsing (e.g., `123`, `123.45`, `1,234`, `$123`, `12%`, `3.2x`, `1.2B`, `1.2 billion`).\n- For each numeric claim, attempt to find support in tool outputs:\n  - Exact match or within tolerance for floats/formatting.\n  - Tolerance rules:\n    - Percent/ratios: absolute tolerance 0.1 (or configurable)\n    - Prices: absolute tolerance 0.5% (or configurable)\n    - Large numbers (market cap): relative tolerance 1%\n  - Accept matches across formatted variants (commas, currency symbols, abbreviations like B/M/K).\n- Penalize unsupported numeric claims.\n- If the answer contains no numeric claims, return a neutral/high score (e.g., 1.0) but include a reason “no numeric claims detected”.\n\n#### Grounding sources\n- Treat only tool results as authoritative grounding.\n- (Optional enhancement): If memory contains previously retrieved tool facts in the same thread, only allow them if they were originally tool-derived and can be linked to a tool event in storage; otherwise don’t count as grounding.\n\n#### Output shape\nExpose a common scorer interface used by Mastra Evals (or a local adapter), e.g.:\n- `id: 'financial_faithfulness'`\n- `score: number`\n- `passed: boolean` (optional) based on threshold\n- `reasons: string[]`\n- `metadata`:\n  - `unsupportedClaims: Array<{ claim: string; number: string; contextSnippet: string }>`\n  - `matchedClaimsCount`, `totalClaimsCount`\n\n### 5) Persist eval runs and scorer results into LibSQL\nCreate a small persistence layer that writes evaluation results to the existing LibSQL DB used by Mastra memory (or a separate DB file, but prefer same DB with new tables).\n\nSchema (proposed):\n- `eval_runs`\n  - `id` TEXT (uuid)\n  - `created_at` INTEGER (epoch ms)\n  - `env` TEXT ('dev'|'prod'|...)\n  - `agent_id` TEXT\n  - `thread_id` TEXT\n  - `resource_id` TEXT\n  - `request_id` TEXT (if available)\n  - `user_message` TEXT (redact/trim if needed)\n  - `assistant_answer` TEXT (redact/trim if needed)\n  - `tool_trace_ref` TEXT (pointer to audit jsonl entry range or blob id)\n  - indexes on `(agent_id, created_at)`, `(thread_id, created_at)`\n- `eval_scores`\n  - `run_id` TEXT (FK to eval_runs)\n  - `scorer_id` TEXT\n  - `score` REAL\n  - `passed` INTEGER\n  - `details_json` TEXT (JSON string for reasons/metadata)\n  - composite index `(scorer_id, run_id)`\n\nImplementation notes:\n- Reuse existing LibSQL client used by memory (Task 9) if possible; otherwise create a dedicated `libsql` connection module under `src/mastra/evals/storage.ts`.\n- Ensure writes are non-blocking for user latency:\n  - fire-and-forget after responding OR\n  - buffer and batch insert in background (simpler: async write after final token; don’t await in HTTP response path).\n- Add lightweight redaction/size limits for stored prompts/answers (e.g., max 8–16KB per field) to avoid DB bloat.\n\n### 6) Add CI eval tests (Bun test) with thresholds\nImplement deterministic evaluation tests that run in CI and fail if quality drops below thresholds.\n\nTest file(s):\n- `test/evals/alphasentry.e2e.test.ts`\n- `test/evals/financial-faithfulness.test.ts`\n\nCI strategy:\n- Use fixed prompts and deterministic tool stubs/mocks where possible.\n- For LLM-based scorers, prefer either:\n  - running them against a mocked scoring backend in CI, or\n  - gating via a dedicated `EVALS_LIVE=true` environment flag and skipping in default CI.\n\nGiven the requirement explicitly asks for CI assertions like `answer relevancy > 0.8`, implement:\n- A “recorded fixture run” mode:\n  - Provide fixture tool results + assistant answer and run scorers over them.\n  - This avoids network calls and makes scores stable.\n- If Mastra Evals built-in scorers require model calls, introduce a test-double scorer implementation for CI that mirrors interface but uses deterministic heuristics; keep a separate optional “live eval” job for real scoring.\n\nThresholds:\n- `answerRelevancy >= 0.8`\n- `completeness >= 0.75` (example)\n- `toxicity >= 0.95` or `toxicityFlag == false` depending on scorer output\n- `promptAlignment >= 0.85`\n- `financialFaithfulness >= 0.9` for numeric answers that must be tool-grounded\n\n### 7) Wire eval visibility for trend monitoring\n- Ensure every persisted eval score includes `env`, `agent_id`, and timestamp.\n- Add a small query helper:\n  - `getEvalTrends({ scorerId, from, to, agentId })` returning daily averages.\n- (Optional, if a UI exists later): keep API-ready endpoints out of this task unless already part of project patterns.\n\n## Acceptance criteria\n- @mastra/evals installed and used.\n- AlphaSentry runs sampled live scorers and persists results to LibSQL.\n- Custom financial faithfulness scorer detects unsupported numeric claims and penalizes score.\n- Sampling policy works (100% dev, 10–20% prod configurable).\n- Bun tests assert eval thresholds using stable fixtures (and/or skip live evals by default but runnable in a dedicated job).\n",
        "testStrategy": "## Local verification\n1) Install & typecheck\n- `bun install`\n- `bun run typecheck`\n\n2) Dev sampling = 100%\n- Set `NODE_ENV=development` and run AlphaSentry through CLI/web with a numeric finance question.\n- Confirm logs show evals executed for the request (e.g., “eval_run_created” + scorer ids).\n\n3) Prod sampling = 10–20%\n- Set `NODE_ENV=production` and `MASTRA_EVALS_SAMPLE_RATE=0.1`.\n- Execute ~30 requests with the same `threadId` (deterministic sampling) and confirm inclusion is stable per thread OR execute different threadIds and confirm ~10% inclusion.\n\n4) Financial faithfulness scorer correctness\n- Run with tool-backed answer (e.g., asks for stock price; ensure tool returns price and answer includes it). Expect `financialFaithfulness >= 0.9`.\n- Introduce an intentionally hallucinated number in a controlled test/fixture (or simulate an agent answer string) and run scorer over the same tool trace; expect score drops significantly (e.g., <= 0.5) and `unsupportedClaims` contains that number.\n\n## Persistence verification (LibSQL)\n5) After a run that triggers evals:\n- Inspect DB (same file as memory or configured eval DB):\n  - Verify `eval_runs` row created with correct agent/thread metadata.\n  - Verify `eval_scores` rows exist for all scorer ids.\n  - Verify `details_json` includes reasons/metadata for custom scorer.\n\n## Automated tests (Bun)\n6) Unit tests\n- `bun test test/evals/financial-faithfulness.test.ts`\n  - Case A: all numbers supported by tool outputs -> expect score >= 0.9\n  - Case B: unsupported number -> expect score <= threshold and reason includes claim\n  - Case C: no numeric claims -> expect score == 1.0 (or defined neutral score)\n\n7) CI threshold test (fixture-based)\n- `bun test test/evals/alphasentry.e2e.test.ts`\n  - Load fixture: { userMessage, toolTrace, assistantAnswer }\n  - Run scorer suite over fixture\n  - Assert `answerRelevancy > 0.8` and other thresholds\n\n8) Optional live eval job (if enabled)\n- With `EVALS_LIVE=true` and required API keys present, run live scoring; otherwise ensure tests skip gracefully without failing CI.\n",
        "status": "pending",
        "dependencies": [
          "6",
          "9"
        ],
        "priority": "high",
        "subtasks": []
      }
    ],
    "metadata": {
      "version": "1.0.0",
      "lastModified": "2026-02-11T01:42:34.852Z",
      "taskCount": 11,
      "completedCount": 6,
      "tags": [
        "master"
      ]
    }
  }
}