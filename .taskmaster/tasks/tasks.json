{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Phase 1 Scaffold: Add Mastra deps, create src/mastra structure, Bun smoke import",
        "description": "Install Mastra packages under Bun, add src/mastra directory scaffolding, and verify Mastra imports cleanly without impacting existing LangChain runtime.",
        "details": "- Create branch `feature/mastra-migration` (per PRD).\n- Install deps with Bun:\n  - `bun add @mastra/core @mastra/memory @mastra/libsql`\n- Immediate Bun import smoke test:\n  - `bun -e \"import { Agent } from '@mastra/core/agent'; import { createTool } from '@mastra/core/tools'; console.log('OK')\"`\n- Create directories/files:\n  - `src/mastra/index.ts`\n  - `src/mastra/agents/dexter.ts`\n  - `src/mastra/tools/index.ts` (empty exports initially)\n- Implement Mastra instance (per PRD):\n  - `src/mastra/index.ts`\n    ```ts\n    import { Mastra } from '@mastra/core';\n    import { dexterAgent } from './agents/dexter.js';\n\n    export const mastra = new Mastra({ agents: { dexterAgent } });\n    ```\n- Implement stub agent:\n  - `src/mastra/agents/dexter.ts`\n    ```ts\n    import { Agent } from '@mastra/core/agent';\n\n    export const dexterAgent = new Agent({\n      id: 'dexter',\n      name: 'Dexter',\n      instructions: 'You are Dexter, a helpful financial research assistant.',\n      model: 'openai/gpt-5.2',\n    });\n    ```\n- Add `src/mastra/smoke-test.ts` to generate a simple response:\n  ```ts\n  import { mastra } from './index.js';\n  const agent = mastra.getAgent('dexterAgent');\n  const response = await agent.generate('What is a P/E ratio?');\n  console.log(response.text);\n  ```\n- Ensure coexistence: do not modify existing `src/agent/*` or LangChain wiring yet.",
        "testStrategy": "- Run Bun import smoke test command; expect `OK`.\n- `bun run src/mastra/smoke-test.ts` prints a non-empty `response.text`.\n- `bun run start` still works (existing LangChain agent unaffected).\n- `bun run typecheck` passes.\n- Validate there are no import collisions by running `bun run typecheck` and ensuring no duplicate type/package conflicts are reported.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-10T23:04:46.936Z"
      },
      {
        "id": 2,
        "title": "Phase 2: Port finance leaf tools to Mastra createTool() (mechanical conversion)",
        "description": "Convert finance leaf tools from LangChain DynamicStructuredTool to Mastra createTool() while preserving API layer, formatting, and prompts unchanged.",
        "details": "- For each finance leaf tool in `src/tools/finance/*.ts`, replace LangChain tool definition with Mastra tool definition:\n  - `name` -> `id`\n  - `schema` -> `inputSchema`\n  - `func` -> `execute`\n  - `new DynamicStructuredTool({ ... })` -> `createTool({ ... })`\n- Preserve the real IP unchanged:\n  - `src/tools/finance/api.ts` (`callApi`, caching, auth) must remain and be called identically.\n  - `src/tools/types.ts` (`formatToolResult`, `parseSearchResults`) must remain and be used.\n  - Domain prompting remains unchanged (do not alter prompt content here).\n- Port tools in PRD order (ensure IDs match existing tool names):\n  - Prices: `get_price_snapshot`, `get_prices`\n  - Fundamentals: `get_income_statements`, `get_balance_sheets`, `get_cash_flow_statements`, `get_all_financial_statements`\n  - Key ratios: `get_key_ratios_snapshot`, `get_key_ratios`\n  - Filings leaf: `get_filings`, `get_10K_filing_items`, `get_10Q_filing_items`, `get_8K_filing_items`\n  - Other: `get_analyst_estimates`, `get_segmented_revenues`, `get_insider_trades`, `get_company_facts`\n  - Crypto: `get_crypto_price_snapshot`, `get_crypto_prices`, `get_crypto_tickers`\n  - News: `get_news`\n- Ensure each tool keeps the same output shape as before (usually `formatToolResult(data, [url])`).\n- Note on progress: remove dependency on `config.metadata.onProgress` from these tool implementations; accept `(input, context)` signature but no progress emission yet.\n\nPseudo-code template for each tool:\n```ts\nimport { createTool } from '@mastra/core/tools';\nimport { z } from 'zod';\nimport { callApi } from './api.js';\nimport { formatToolResult } from '../types.js';\n\nexport const someTool = createTool({\n  id: 'tool_id',\n  description: '...',\n  inputSchema: z.object({ /* existing schema */ }),\n  execute: async (input, context) => {\n    // context.abortSignal may be used if supported by callApi\n    const { data, url } = await callApi('/endpoint/', { /* ... */ });\n    return formatToolResult(data?.something ?? {}, [url]);\n  },\n});\n```",
        "testStrategy": "- Add/adjust unit tests per module (or adapt existing) to call `tool.execute()` directly with mocked `callApi`:\n  - Example (pseudo):\n    ```ts\n    vi.mock('./api', () => ({ callApi: vi.fn(async ()=>({data:{...}, url:'u'})) }));\n    const out = await getPriceSnapshot.execute({ ticker:'AAPL' } as any, {} as any);\n    expect(out).toMatchObject({ data: expect.anything(), sourceUrls: ['u'] });\n    ```\n- Run: `bun test src/tools/finance/*.test.ts`.\n- `bun run typecheck`.\n- `bun run start` still works (LangChain agent path still in place until Phase 3/5).",
        "priority": "high",
        "dependencies": [
          "1"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-11T00:28:07.168Z"
      },
      {
        "id": 3,
        "title": "Phase 2: Port non-finance leaf tools (search, browser, skill) to createTool()",
        "description": "Convert Exa/Tavily web_search variants, browser tool, and skill tool to Mastra createTool() while preserving behavior and output formatting contracts.",
        "details": "- Port the following tools to `createTool()`:\n  - `web_search` (Exa variant) in `src/tools/search/`\n  - `web_search` (Tavily variant) in `src/tools/search/`\n  - `browser` in `src/tools/browser/`\n  - `skill` in `src/tools/skill.ts`\n- Ensure tool IDs remain stable (`id: 'web_search'` etc.). If there are two variants, keep unique IDs (or keep existing runtime selection mechanism) consistent with current code; do not change user-facing tool naming without PRD direction.\n- Keep `src/skills/` system intact; skill tool should still load SKILL.md workflows as before.\n- Keep output formatting compatible with existing UI expectations (`formatToolResult` / `parseSearchResults` usage where applicable).\n\nImplementation notes:\n- For tools that previously relied on LangChain callback manager / metadata for progress, accept `(input, context)` but do not implement progress emission yet.\n- Ensure network calls can be aborted if `context.abortSignal` is available; thread abort signal down where possible.\n\nPseudo-code (pattern):\n```ts\nexport const webSearch = createTool({\n  id: 'web_search',\n  description: '...',\n  inputSchema: z.object({ query: z.string(), /* ... */ }),\n  execute: async (input, context) => {\n    // call provider SDK\n    // return parseSearchResults(...) or formatToolResult(...)\n  },\n});\n```",
        "testStrategy": "- Unit tests for each tool calling `.execute()` with mocked provider clients.\n- Validate schemas compile and tool exports are typed.\n- `bun run typecheck`.\n- Smoke test by running a minimal Mastra agent (from Phase 1) with one of these tools temporarily registered locally (or in a small test agent) and verifying it can call `web_search`/`browser` and return formatted results.",
        "priority": "high",
        "dependencies": [
          "1"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-11T00:45:10.748Z"
      },
      {
        "id": 4,
        "title": "Phase 2: Create Mastra tool registry (src/mastra/tools/index.ts) for all ported leaf tools",
        "description": "Create a Mastra-compatible tool registry that re-exports the ported tools without touching the existing LangChain registry yet.",
        "details": "- Implement `src/mastra/tools/index.ts` as the new tool registry used by the Mastra agent.\n- Import tools from existing locations (`src/tools/finance/*`, `src/tools/search/*`, `src/tools/browser/*`, `src/tools/skill.ts`) and export grouped registries:\n  - `financeLeafTools` (all finance leaf tools)\n  - `allLeafTools` (finance + non-finance leaf)\n- Keep this file side-by-side with existing registry. Do not delete old registry until Phase 5.\n\nExample skeleton:\n```ts\n// src/mastra/tools/index.ts\nimport { getPriceSnapshot, getPrices } from '../../tools/finance/prices.js';\n// ... all other leaf tool imports\nimport { webSearch as webSearchExa } from '../../tools/search/exa.js';\nimport { webSearch as webSearchTavily } from '../../tools/search/tavily.js';\nimport { browser } from '../../tools/browser/index.js';\nimport { skill } from '../../tools/skill.js';\n\nexport const financeLeafTools = {\n  getPriceSnapshot,\n  getPrices,\n  // ...\n};\n\nexport const allLeafTools = {\n  ...financeLeafTools,\n  // decide how to expose search variants (keep existing selection behavior)\n  browser,\n  skill,\n};\n```\n- If the current code switches between Exa/Tavily at runtime, implement a thin wrapper tool with stable id that dispatches to the configured variant (do not implement meta-tool routing here; keep simple config-based dispatch).",
        "testStrategy": "- `bun run typecheck` ensures the registry exports a valid object map.\n- Add a small test that iterates over `Object.values(allLeafTools)` and asserts each has expected shape: `{ id, execute, inputSchema }`.\n- Ensure no runtime import errors under Bun by running `bun -e \"import('./src/mastra/tools/index.ts').then(m=>console.log(Object.keys(m.allLeafTools).length))\"`.",
        "priority": "high",
        "dependencies": [
          "2",
          "3"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-11T01:06:01.620Z"
      },
      {
        "id": 5,
        "title": "Phase 3: Implement meta-tools financial_search and read_filings using sub-agents wrapped as Mastra tools",
        "description": "Port LangChain meta-tools to Mastra by creating createTool() wrappers that internally run sub-agents using the leaf tool registry, preserving existing output contracts and prompt policies.",
        "details": "- Implement `src/mastra/tools/financial-search.ts` as per PRD:\n  - Create a `financialRouter` sub-agent with:\n    - `id: 'financial-router'`\n    - `instructions: buildRouterPrompt()` (reuse existing router prompt content)\n    - `model: 'openai/gpt-5.2'`\n    - `tools: financeLeafTools` (registered directly)\n  - Wrap in `createTool({ id: 'financial_search', ... })`.\n  - In `execute`, call `financialRouter.generate(input.query, { maxSteps: 3 })`.\n  - Implement `combineFinancialResults(result.steps)` to aggregate tool outputs into the same `{ data, sourceUrls }` contract expected by the system prompt and UI.\n\n- Implement `src/mastra/tools/read-filings.ts` as per PRD:\n  - Two-step sub-agent workflow:\n    1) identify/select filing metadata (likely calls `get_filings`)\n    2) retrieve and extract requested filing items (calls `get_10K_filing_items` / `get_10Q_filing_items` / `get_8K_filing_items`)\n  - Wrap as `createTool({ id: 'read_filings', ... })`.\n  - Ensure it respects the existing two-step behavior and returns formatted results.\n\n- Update `src/mastra/tools/index.ts` to export these meta-tools and create `allTools`:\n  - `allTools = { ...allLeafTools, financialSearch, readFilings }`\n\nPseudo-code for aggregation:\n```ts\nfunction combineFinancialResults(steps){\n  const data = [];\n  const sourceUrls = new Set();\n  for (const s of steps){\n    if (s.toolResult?.data) data.push(s.toolResult.data);\n    for (const u of (s.toolResult?.sourceUrls ?? [])) sourceUrls.add(u);\n  }\n  return { data, sourceUrls: [...sourceUrls] };\n}\n```\n(Adjust to match the exact output shape used in `formatToolResult`.)",
        "testStrategy": "- Unit tests with mocked sub-agent behavior (or integration tests with mocked leaf tools):\n  - Stub `financeLeafTools` tools to return deterministic results and verify aggregation merges `sourceUrls` and preserves `data` shape.\n- Integration smoke test:\n  - Create a small script to call `financial_search.execute({query:'AAPL PE ratio'})` and assert it returns structured output.\n- Ensure `read_filings` executes two-step flow by asserting it calls expected underlying tools in order (via spies/mocks).",
        "priority": "high",
        "dependencies": [
          "4"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-11T01:21:21.457Z"
      },
      {
        "id": 6,
        "title": "Phase 3: Wire full system prompt + tools into Mastra Dexter agent; replace custom agent loop usage in runner hook",
        "description": "Update Mastra Dexter agent to use existing buildSystemPrompt(), register all tools, and switch the app runner to Mastra agent streaming with maxSteps.",
        "details": "- Update `src/mastra/agents/dexter.ts`:\n  - Use existing prompt builder `buildSystemPrompt()` from `src/agent/prompts.js`.\n  - Register `allTools` from `src/mastra/tools/index.ts`.\n  - Set `model: 'openai/gpt-5.2'`.\n  - Use Mastra `maxSteps` instead of custom while/iteration loop when running.\n\nExample:\n```ts\nimport { Agent } from '@mastra/core/agent';\nimport { buildSystemPrompt } from '../../agent/prompts.js';\nimport { allTools } from '../tools/index.js';\n\nexport const dexterAgent = new Agent({\n  id: 'dexter',\n  name: 'Dexter',\n  instructions: buildSystemPrompt('openai/gpt-5.2'),\n  model: 'openai/gpt-5.2',\n  tools: allTools,\n});\n```\n\n- Update `src/hooks/use-agent-runner.ts` to use:\n  - `const agent = mastra.getAgent('dexterAgent')`\n  - `const stream = await agent.stream(query, { maxSteps: 10 })`\n  - Consume via event bridge generator (implemented in Task 7).\n\nPseudo-code runner change:\n```ts\nconst agent = mastra.getAgent('dexterAgent');\nconst stream = await agent.stream(query, { maxSteps: 10, signal });\nfor await (const evt of bridgeEvents(stream)) {\n  dispatch(evt);\n}\n```",
        "testStrategy": "- Run `bun run src/mastra/smoke-test.ts \"What is Apple's current stock price?\"` and confirm tool usage (may require observing step events/logging).\n- Run CLI `bun run start` and execute a financial query; confirm it completes and produces an answer.\n- `bun run typecheck` passes.\n- Verify maxSteps prevents infinite loops by crafting a prompt that would previously loop; ensure it stops after configured steps.",
        "priority": "high",
        "dependencies": [
          "1",
          "5"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-11T01:42:18.164Z"
      },
      {
        "id": 7,
        "title": "Phase 3: Implement Mastra→AgentEvent event bridge for CLI/Web parity + add JSONL audit log (scratchpad as audit trail)",
        "description": "Create an event bridge mapping Mastra streaming events to existing AgentEvent types and implement append-only JSONL audit logging of tool calls/results.",
        "details": "- Implement `src/mastra/event-bridge.ts` exporting `bridgeEvents(...)` that yields existing `AgentEvent` from `src/agent/types.js`.\n- Mapping requirements (PRD): Ink CLI/web currently expect events like `tool_start`, `tool_end`, `thinking`, `answer_start`, `done`.\n- Use Mastra `agent.stream()` hooks/callbacks:\n  - Use `onStepFinish` (passed in stream options) to detect tool calls/results and emit:\n    - `tool_start` when a tool call is detected (if Mastra provides pre-call hook, otherwise emit start when call appears and end when result is present).\n    - `tool_end` when result is available.\n  - For text streaming, forward incremental tokens/chunks as existing text/answer events (depending on current `AgentEvent` contract).\n\n- Implement `src/mastra/audit-log.ts` JSONL logger:\n  - Append-only file under `.dexter/scratchpad/` (per PRD).\n  - Record `{ ts, thread, tool, args, resultSummary, sourceUrls, toolCallId }`.\n\nPseudo-code audit log:\n```ts\nimport { mkdir, appendFile } from 'node:fs/promises';\nexport async function appendAudit(entry){\n  await mkdir('.dexter/scratchpad', { recursive: true });\n  await appendFile('.dexter/scratchpad/audit.jsonl', JSON.stringify(entry)+'\\n');\n}\n```\n\n- Wire audit log via `onStepFinish` in runner/web route later:\n```ts\nonStepFinish: ({ toolCalls, toolResults }) => {\n  // iterate and appendAudit(...)\n}\n```\n- Maintain scratchpad decision: audit trail only; no context management responsibilities.",
        "testStrategy": "- Unit test `bridgeEvents` with a mocked Mastra stream iterator emitting representative events; assert correct `AgentEvent` outputs.\n- Manual CLI run: confirm tool events appear (start/end) and final answer prints.\n- Verify `.dexter/scratchpad/audit.jsonl` is created and grows with tool calls.\n- Ensure audit logging does not crash if directory missing; test first-run scenario.",
        "priority": "high",
        "dependencies": [
          "6"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-11T01:51:48.683Z"
      },
      {
        "id": 8,
        "title": "Phase 3: Update model selection to Mastra model router strings (multi-provider support)",
        "description": "Replace LangChain LLM wrappers with Mastra model router string selection and verify at least OpenAI + one other provider path works, with OpenRouter fallback where needed.",
        "details": "- Update `src/model/llm.ts` behavior to return Mastra model identifiers (or introduce a new module, but PRD later deletes `src/model/llm.ts`; for now implement the needed function and later remove old LangChain code).\n- Implement a function, e.g. `getMastraModelString(provider, model)` that returns strings like:\n  - OpenAI: `'openai/gpt-5.2'`\n  - Anthropic: `'anthropic/claude-sonnet-4'`\n  - Google: `'google/gemini-3-flash-preview'`\n  - Ollama: `'ollama/llama3'`\n  - xAI/Grok/Moonshot/DeepSeek: if not directly supported, use OpenRouter fallback per PRD:\n    - e.g. `'openrouter:xai/grok-4-1-fast-reasoning'`\n- Ensure `dexterAgent` uses the selected model string.\n- If prompt caching is used for Anthropic, pass via `instructions` object with `providerOptions.anthropic.cacheControl.type = 'ephemeral'` as in PRD.\n\nPseudo-code:\n```ts\nexport function getMastraModelString({ provider, model }: {provider:string; model:string}) {\n  if (provider === 'openai') return `openai/${model}`;\n  if (provider === 'anthropic') return `anthropic/${model}`;\n  if (provider === 'google') return `google/${model}`;\n  if (provider === 'ollama') return `ollama/${model}`;\n  if (provider === 'openrouter') return `openrouter:${model}`;\n  return `openai/${model}`; // safe default per current PRD focus\n}\n```",
        "testStrategy": "- Unit test mapping table inputs → expected strings.\n- Manual runtime test:\n  - Configure OpenAI model and run `src/mastra/smoke-test.ts`.\n  - Configure a second provider (e.g., Anthropic) and verify a response is produced.\n- `bun run typecheck` to ensure no LangChain class imports remain in the model selection path used by Mastra agent.",
        "priority": "high",
        "dependencies": [
          "6"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-11T01:51:50.606Z"
      },
      {
        "id": 9,
        "title": "Phase 4: Add Mastra Memory (LibSQL store/vector, working memory template, semantic recall) + thread/resource wiring",
        "description": "Implement Mastra Memory with LibSQL-backed persistence, configure message history/working memory/semantic recall, and wire thread/resource IDs for CLI and web sessions.",
        "details": "- Implement LibSQL storage + vector in `src/mastra/index.ts` or `src/mastra/memory.ts` per PRD:\n  - `LibSQLStore({ id, url: 'file:.dexter/memory.db' })`\n  - `LibSQLVector({ id, url: 'file:.dexter/memory.db' })`\n- Implement `src/mastra/memory.ts`:\n  - Create `Memory` instance with:\n    - `embedder: new ModelRouterEmbeddingModel('openai/text-embedding-3-small')`\n    - options:\n      - `lastMessages: 20`\n      - workingMemory enabled with the provided template\n      - semanticRecall: `{ topK: 5, messageRange: 2, scope: 'resource' }`\n- Wire `memory` onto `dexterAgent` in `src/mastra/agents/dexter.ts`.\n- Update runner(s) to pass memory identifiers:\n  - CLI: `thread: cli-${sessionId}`, `resource: 'cli-user'`\n  - Web: `thread: web-${sessionId}`, `resource: user-${sessionId}`\n\nPseudo-code for calling:\n```ts\nawait agent.stream(query, {\n  maxSteps: 10,\n  memory: { thread, resource },\n});\n```\n- Note: PRD indicates existing InMemoryChatHistory/Redis becomes unnecessary after this; do not remove yet until Phase 6 cleanup, but stop relying on it where the Mastra path is used.",
        "testStrategy": "- Run multi-turn smoke test:\n  1) Ask: \"What is AAPL's P/E ratio?\"\n  2) Follow-up: \"How does it compare to MSFT?\"\n  Expect agent to retain AAPL context within same thread.\n- Restart process and ask: \"what were we looking at?\" using same resource; expect working memory/semantic recall to surface prior context.\n- Verify `.dexter/memory.db` is created and non-empty.\n- `bun run typecheck` passes.",
        "priority": "high",
        "dependencies": [
          "6"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-11T01:59:57.220Z"
      },
      {
        "id": 10,
        "title": "Phase 5–6: Remove LangChain/LangSmith, finalize Mastra-only path, and implement Vercel AI SDK streaming in Next.js route",
        "description": "Strip LangChain dependencies and dead code, migrate web API chat route to true token streaming via Vercel AI SDK adapter, and remove fake SSE drip + Redis session logic.",
        "details": "Phase 5 (dependency/code removal):\n- Remove deps:\n  - `bun remove @langchain/core @langchain/openai @langchain/anthropic @langchain/google-genai @langchain/ollama @langchain/exa @langchain/tavily langsmith`\n- Delete/replace files as specified:\n  - Delete `src/agent/agent.ts` (custom Agent)\n  - Delete `src/tools/registry.ts` (old registry)\n  - Delete `src/model/llm.ts` (if still present per PRD) and ensure model routing uses Mastra model strings (Task 8)\n  - Keep `src/agent/prompts.ts` and `src/agent/types.ts`\n  - Ensure `src/agent/scratchpad.ts` becomes audit-log-only or is replaced by `src/mastra/audit-log.ts` with no LangChain imports\n- Replace LangSmith tracing with Mastra OpenTelemetry tracing (configure Mastra logger/tracing in `src/mastra/index.ts` per PRD; keep minimal logger configuration).\n\nPhase 6 (web streaming with Vercel AI SDK):\n- In `web/`:\n  - `bun add @mastra/core @mastra/ai-sdk`\n- Replace `web/app/api/chat/route.ts`:\n  - Use Mastra agent stream and `toAISdkV5Stream` adapter:\n    ```ts\n    import { mastra } from '../../../src/mastra/index.js';\n    import { toAISdkV5Stream } from '@mastra/ai-sdk';\n\n    export const runtime = 'nodejs';\n    export const maxDuration = 300;\n\n    export async function POST(req: Request) {\n      const { messages, sessionId } = await req.json();\n      const query = messages[messages.length - 1]?.content;\n      const agent = mastra.getAgent('dexterAgent');\n      const sid = sessionId || crypto.randomUUID();\n\n      const stream = await agent.stream(query, {\n        maxSteps: 5,\n        memory: { thread: `web-${sid}`, resource: `user-${sid}` },\n        onStepFinish: ({ toolCalls, toolResults }) => {\n          // optional: audit log append\n        },\n      });\n\n      const aiStream = toAISdkV5Stream(stream, { from: 'agent' });\n      return new Response(aiStream, {\n        headers: {\n          'Content-Type': 'text/event-stream',\n          'Cache-Control': 'no-cache',\n        },\n      });\n    }\n    ```\n- Update frontend component to use `useChat` from `ai/react`:\n  - Ensure it renders streaming tokens and (optionally) tool event parts.\n- Remove dead code in web route:\n  - delete fake word-by-word delay, SSE encoder helpers, sendEvent/sendText helpers, LangSmith wrappers, and Redis session management.\n\nFinal verification/cleanup:\n- Ensure no `@langchain` imports remain (`grep -r \"@langchain\" src/ web/`).\n- Ensure no `langsmith` imports remain in `web/`.",
        "testStrategy": "Phase 5 tests:\n- `grep -r \"@langchain\" src/ --include=\"*.ts\" --include=\"*.tsx\"` returns zero.\n- `bun run typecheck` passes.\n- `bun test` passes.\n- `bun run start` works end-to-end (CLI) with Mastra.\n\nPhase 6 tests:\n- In `web/`: `bun run build` succeeds; `bun run dev` starts.\n- Browser manual:\n  1) Send \"What is AAPL's P/E ratio?\" and confirm true token streaming (no artificial delays).\n  2) Confirm tool call/result events are visible/handled if UI supports them.\n  3) Send follow-up \"How does it compare to MSFT?\" and confirm memory continuity.\n- Confirm no `langsmith` imports in `web/` via grep.",
        "priority": "high",
        "dependencies": [
          "7",
          "8",
          "9"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-02-11T02:11:05.783Z"
      },
      {
        "id": 11,
        "title": "Add Mastra Evals (scorers) across AlphaSentry agent lifecycle with CI gating and LibSQL trend storage",
        "description": "Install and integrate @mastra/evals, attach live evaluation scorers to the AlphaSentry agent (including a custom financial faithfulness scorer grounded in tool results), configure environment-based sampling, persist results to LibSQL, and add Bun CI eval tests with quality thresholds.",
        "details": "## Scope\nImplement runtime and CI-time evaluation for AlphaSentry using Mastra Evals. This includes built-in scorers (answer relevancy, completeness, toxicity, prompt alignment) plus a custom financial faithfulness scorer that flags hallucinated numbers by verifying the final answer is supported by tool outputs captured during the run.\n\n## Prerequisites/assumptions\n- AlphaSentry is already wired to Mastra tools (tool registry + agent tool wiring) and emits/records tool calls/results (directly or via an event bridge / audit log).\n- Memory is already wired so that eval context can include recent conversation state (where appropriate).\n\n## Dependencies\n- Depends on Phase 3 tool wiring (Task 6) so tool results are available to ground the custom scorer.\n- Depends on Phase 4 memory wiring (Task 9) so scorer context can reference thread/resource history and so storage primitives (LibSQL) are available/consistent.\n\n## Implementation plan\n\n### 1) Install dependency and add wiring points\n- Add dependency:\n  - `bun add @mastra/evals`\n- Create module structure:\n  - `src/mastra/evals/index.ts` – exports scorer factory/wiring helper.\n  - `src/mastra/evals/faithfulness-financial.ts` – custom scorer implementation.\n  - `src/mastra/evals/storage.ts` – LibSQL persistence for eval runs + scores.\n  - `src/mastra/evals/config.ts` – sampling rates and enable/disable flags.\n\n### 2) Define sampling/config policy (dev 100%, prod 10–20%)\nImplement a small config helper that chooses whether to run evals for a given request:\n- Environment-based defaults:\n  - `NODE_ENV !== 'production'`: sample rate = 1.0\n  - `NODE_ENV === 'production'`: sample rate = 0.1 (or configurable up to 0.2)\n- Allow overrides with env vars:\n  - `MASTRA_EVALS_ENABLED=true|false` (default true in dev, true in prod)\n  - `MASTRA_EVALS_SAMPLE_RATE=0..1` (default as above)\n- Deterministic sampling option for stability (recommended): hash of `threadId` or `requestId` to decide inclusion (prevents flapping across requests).\n\n### 3) Attach live scorers to AlphaSentry agent lifecycle\nUpdate the AlphaSentry agent definition (e.g., `src/mastra/agents/alphaSentry.ts` or wherever the agent is defined) to run scorers on completed turns.\n\nImplementation approach (choose one based on Mastra API surface available in this repo):\n- Option A: Use Mastra Evals “live scorers” integration (preferred):\n  - Configure the agent with eval hooks/callbacks that receive:\n    - prompt/system prompt\n    - messages (user + assistant)\n    - tool calls/results (per step)\n    - final assistant output\n- Option B: If agent API doesn’t directly support eval hooks, wrap the runner:\n  - After `agent.stream()` completes, collect:\n    - final text\n    - conversation messages\n    - tool execution transcript (from event bridge/audit log in the same run)\n  - Invoke scorers manually, then persist.\n\nAttach these scorers:\n- `answerRelevancy` (how well the answer matches the user query)\n- `completeness` (coverage of user request)\n- `toxicity` (safety)\n- `promptAlignment` (adherence to system/policy constraints)\n- `financialFaithfulness` (custom)\n\nEnsure scorers run only when sampling allows; otherwise skip with minimal overhead.\n\n### 4) Implement custom financial faithfulness scorer\nGoal: Verify that *numerical claims* in the final answer are grounded in tool results produced during the run (no hallucinated numbers).\n\n#### Inputs required\n- Final assistant answer text.\n- Tool results transcript for that run (preferably structured):\n  - tool name/id\n  - input\n  - output (raw JSON/text)\n  - timestamps\n- Optional: the user question (to focus evaluation).\n\n#### Scoring behavior\nReturn a normalized score (0..1) and reasons.\nRecommended rubric:\n- Extract candidate numeric claims from final answer:\n  - currency amounts, percentages, ratios, prices, market cap, P/E, EPS, revenue, growth rates, dates with numbers, etc.\n  - Use regex + lightweight parsing (e.g., `123`, `123.45`, `1,234`, `$123`, `12%`, `3.2x`, `1.2B`, `1.2 billion`).\n- For each numeric claim, attempt to find support in tool outputs:\n  - Exact match or within tolerance for floats/formatting.\n  - Tolerance rules:\n    - Percent/ratios: absolute tolerance 0.1 (or configurable)\n    - Prices: absolute tolerance 0.5% (or configurable)\n    - Large numbers (market cap): relative tolerance 1%\n  - Accept matches across formatted variants (commas, currency symbols, abbreviations like B/M/K).\n- Penalize unsupported numeric claims.\n- If the answer contains no numeric claims, return a neutral/high score (e.g., 1.0) but include a reason “no numeric claims detected”.\n\n#### Grounding sources\n- Treat only tool results as authoritative grounding.\n- (Optional enhancement): If memory contains previously retrieved tool facts in the same thread, only allow them if they were originally tool-derived and can be linked to a tool event in storage; otherwise don’t count as grounding.\n\n#### Output shape\nExpose a common scorer interface used by Mastra Evals (or a local adapter), e.g.:\n- `id: 'financial_faithfulness'`\n- `score: number`\n- `passed: boolean` (optional) based on threshold\n- `reasons: string[]`\n- `metadata`:\n  - `unsupportedClaims: Array<{ claim: string; number: string; contextSnippet: string }>`\n  - `matchedClaimsCount`, `totalClaimsCount`\n\n### 5) Persist eval runs and scorer results into LibSQL\nCreate a small persistence layer that writes evaluation results to the existing LibSQL DB used by Mastra memory (or a separate DB file, but prefer same DB with new tables).\n\nSchema (proposed):\n- `eval_runs`\n  - `id` TEXT (uuid)\n  - `created_at` INTEGER (epoch ms)\n  - `env` TEXT ('dev'|'prod'|...)\n  - `agent_id` TEXT\n  - `thread_id` TEXT\n  - `resource_id` TEXT\n  - `request_id` TEXT (if available)\n  - `user_message` TEXT (redact/trim if needed)\n  - `assistant_answer` TEXT (redact/trim if needed)\n  - `tool_trace_ref` TEXT (pointer to audit jsonl entry range or blob id)\n  - indexes on `(agent_id, created_at)`, `(thread_id, created_at)`\n- `eval_scores`\n  - `run_id` TEXT (FK to eval_runs)\n  - `scorer_id` TEXT\n  - `score` REAL\n  - `passed` INTEGER\n  - `details_json` TEXT (JSON string for reasons/metadata)\n  - composite index `(scorer_id, run_id)`\n\nImplementation notes:\n- Reuse existing LibSQL client used by memory (Task 9) if possible; otherwise create a dedicated `libsql` connection module under `src/mastra/evals/storage.ts`.\n- Ensure writes are non-blocking for user latency:\n  - fire-and-forget after responding OR\n  - buffer and batch insert in background (simpler: async write after final token; don’t await in HTTP response path).\n- Add lightweight redaction/size limits for stored prompts/answers (e.g., max 8–16KB per field) to avoid DB bloat.\n\n### 6) Add CI eval tests (Bun test) with thresholds\nImplement deterministic evaluation tests that run in CI and fail if quality drops below thresholds.\n\nTest file(s):\n- `test/evals/alphasentry.e2e.test.ts`\n- `test/evals/financial-faithfulness.test.ts`\n\nCI strategy:\n- Use fixed prompts and deterministic tool stubs/mocks where possible.\n- For LLM-based scorers, prefer either:\n  - running them against a mocked scoring backend in CI, or\n  - gating via a dedicated `EVALS_LIVE=true` environment flag and skipping in default CI.\n\nGiven the requirement explicitly asks for CI assertions like `answer relevancy > 0.8`, implement:\n- A “recorded fixture run” mode:\n  - Provide fixture tool results + assistant answer and run scorers over them.\n  - This avoids network calls and makes scores stable.\n- If Mastra Evals built-in scorers require model calls, introduce a test-double scorer implementation for CI that mirrors interface but uses deterministic heuristics; keep a separate optional “live eval” job for real scoring.\n\nThresholds:\n- `answerRelevancy >= 0.8`\n- `completeness >= 0.75` (example)\n- `toxicity >= 0.95` or `toxicityFlag == false` depending on scorer output\n- `promptAlignment >= 0.85`\n- `financialFaithfulness >= 0.9` for numeric answers that must be tool-grounded\n\n### 7) Wire eval visibility for trend monitoring\n- Ensure every persisted eval score includes `env`, `agent_id`, and timestamp.\n- Add a small query helper:\n  - `getEvalTrends({ scorerId, from, to, agentId })` returning daily averages.\n- (Optional, if a UI exists later): keep API-ready endpoints out of this task unless already part of project patterns.\n\n## Acceptance criteria\n- @mastra/evals installed and used.\n- AlphaSentry runs sampled live scorers and persists results to LibSQL.\n- Custom financial faithfulness scorer detects unsupported numeric claims and penalizes score.\n- Sampling policy works (100% dev, 10–20% prod configurable).\n- Bun tests assert eval thresholds using stable fixtures (and/or skip live evals by default but runnable in a dedicated job).\n",
        "testStrategy": "## Local verification\n1) Install & typecheck\n- `bun install`\n- `bun run typecheck`\n\n2) Dev sampling = 100%\n- Set `NODE_ENV=development` and run AlphaSentry through CLI/web with a numeric finance question.\n- Confirm logs show evals executed for the request (e.g., “eval_run_created” + scorer ids).\n\n3) Prod sampling = 10–20%\n- Set `NODE_ENV=production` and `MASTRA_EVALS_SAMPLE_RATE=0.1`.\n- Execute ~30 requests with the same `threadId` (deterministic sampling) and confirm inclusion is stable per thread OR execute different threadIds and confirm ~10% inclusion.\n\n4) Financial faithfulness scorer correctness\n- Run with tool-backed answer (e.g., asks for stock price; ensure tool returns price and answer includes it). Expect `financialFaithfulness >= 0.9`.\n- Introduce an intentionally hallucinated number in a controlled test/fixture (or simulate an agent answer string) and run scorer over the same tool trace; expect score drops significantly (e.g., <= 0.5) and `unsupportedClaims` contains that number.\n\n## Persistence verification (LibSQL)\n5) After a run that triggers evals:\n- Inspect DB (same file as memory or configured eval DB):\n  - Verify `eval_runs` row created with correct agent/thread metadata.\n  - Verify `eval_scores` rows exist for all scorer ids.\n  - Verify `details_json` includes reasons/metadata for custom scorer.\n\n## Automated tests (Bun)\n6) Unit tests\n- `bun test test/evals/financial-faithfulness.test.ts`\n  - Case A: all numbers supported by tool outputs -> expect score >= 0.9\n  - Case B: unsupported number -> expect score <= threshold and reason includes claim\n  - Case C: no numeric claims -> expect score == 1.0 (or defined neutral score)\n\n7) CI threshold test (fixture-based)\n- `bun test test/evals/alphasentry.e2e.test.ts`\n  - Load fixture: { userMessage, toolTrace, assistantAnswer }\n  - Run scorer suite over fixture\n  - Assert `answerRelevancy > 0.8` and other thresholds\n\n8) Optional live eval job (if enabled)\n- With `EVALS_LIVE=true` and required API keys present, run live scoring; otherwise ensure tests skip gracefully without failing CI.\n",
        "status": "pending",
        "dependencies": [
          "6",
          "9"
        ],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 12,
        "title": "Provision Turso (hosted LibSQL) production database for Mastra Memory persistence",
        "description": "Create and configure a Turso-hosted LibSQL database for production memory persistence, capture connection credentials, and validate the CLI agent can read/write memory against the remote database via env vars.",
        "status": "pending",
        "dependencies": [
          9
        ],
        "priority": "high",
        "details": "## Goal\nMove Mastra Memory persistence from local file-backed LibSQL (e.g., `file:.dexter/memory.db`) to a Turso-hosted LibSQL instance for production usage, while keeping local development behavior intact.\n\n## Prerequisites\n- Mastra Memory is already wired to use LibSQL store/vector and reads `LIBSQL_URL` / `LIBSQL_AUTH_TOKEN` (or equivalent) from environment (Task 9).\n\n## Steps\n\n### 1) Create Turso org/account and authenticate\n1. Create/login to Turso account (and org if required by your setup).\n2. Install Turso CLI (if not already): follow Turso docs for your OS.\n3. Authenticate:\n   - `turso auth login`\n\n### 2) Create the production database\nCreate the DB named exactly `alpha-sentry`:\n- `turso db create alpha-sentry`\n\nConfirm it exists:\n- `turso db list`\n\n### 3) Generate an auth token\nGenerate a token for the database:\n- `turso db tokens create alpha-sentry`\n\nStore the token securely (password manager / secret manager). Avoid committing to git.\n\n### 4) Record connection values (LIBSQL_URL + LIBSQL_AUTH_TOKEN)\n1. Retrieve the DB URL:\n   - `turso db show alpha-sentry` (or the Turso CLI command that prints the database URL/hostname)\n2. Record the values to be used by the app:\n   - `LIBSQL_URL` (e.g., `libsql://<db-hostname>`)\n   - `LIBSQL_AUTH_TOKEN` (the generated token)\n\n### 5) Define environment configuration conventions\nAdd/update documentation and example env files:\n- Update `README` (or `docs/`) with a “Production Memory (Turso)” section that includes:\n  - Required env vars: `LIBSQL_URL`, `LIBSQL_AUTH_TOKEN`\n  - Guidance: do not commit secrets; use `.env.local` for local validation and platform secret store (Vercel/Render/etc.) for production.\n- If the repo uses `.env.example`, add placeholders:\n  - `LIBSQL_URL=libsql://...`\n  - `LIBSQL_AUTH_TOKEN=...`\n\n### 6) Ensure code uses env vars to switch between local and remote\nVerify the Mastra Memory LibSQL initialization:\n- Prefers Turso remote when `LIBSQL_URL` is set.\n- Falls back to local `file:.dexter/memory.db` when not set (dev convenience).\n\nIf this behavior is not already present, implement a minimal selection in the memory config module (where Task 9 wired LibSQL):\n- `const url = process.env.LIBSQL_URL ?? 'file:.dexter/memory.db'`\n- `const authToken = process.env.LIBSQL_AUTH_TOKEN` (pass only when defined)\n\nImportant: Do not log the auth token. If logging connection info, redact sensitive parts.\n\n### 7) Operational notes\n- Decide whether to create separate DBs for staging vs prod (optional, but recommended). If doing so, document naming and env var mapping.\n- Verify any “thread/resource” identifiers used by memory are stable across restarts so you can confirm persistence.\n\nDeliverables:\n- Turso DB `alpha-sentry` exists.\n- Token created and securely stored.\n- `LIBSQL_URL` and `LIBSQL_AUTH_TOKEN` recorded for deployment.\n- Repo docs updated with configuration instructions.\n- (If needed) small code tweak to ensure env-var-based remote selection works cleanly without breaking local fallback.",
        "testStrategy": "## Local connection validation (remote Turso)\n1. Export env vars in your shell (do not commit):\n   - `export LIBSQL_URL=\"<your libsql://... url>\"`\n   - `export LIBSQL_AUTH_TOKEN=\"<your token>\"`\n2. Run the CLI agent in a way that uses Mastra Memory and a stable thread/resource id (whatever the project uses—e.g., a fixed `--thread` / `--resource` option or persisted session identifier).\n3. In the first run, ask the agent something that should be remembered (within the same thread/resource):\n   - Prompt A: “Remember that my favorite tickers are AAPL and MSFT.”\n   - Then: “What are my favorite tickers?”\n   Expect: the agent recalls AAPL/MSFT.\n4. Stop the process completely.\n5. Start the CLI agent again with the same thread/resource identifier.\n6. Ask: “What are my favorite tickers?”\n   Expect: the agent still recalls AAPL/MSFT after restart, indicating persistence against Turso.\n\n## Negative / fallback sanity check\n7. Unset env vars:\n   - `unset LIBSQL_URL LIBSQL_AUTH_TOKEN`\n8. Run the CLI again and ensure it still works using local file-backed storage (no crashes; memory works within the session).\n\n## Safety checks\n9. Confirm no secrets are printed to logs:\n   - Grep runtime logs/output to ensure `LIBSQL_AUTH_TOKEN` is not present.\n\n## Documentation check\n10. Verify `README`/docs and `.env.example` (if present) clearly list `LIBSQL_URL` and `LIBSQL_AUTH_TOKEN` and describe how to configure Turso for production.",
        "subtasks": []
      },
      {
        "id": 13,
        "title": "Configure Vercel environment variables for feature/mastra-migration and redeploy to fix /api/chat ConnectionFailed",
        "description": "Add required production environment variables to the Vercel project for the feature/mastra-migration branch, trigger a redeploy, and confirm the Next.js /api/chat endpoint returns 200 and streams tokens instead of a 500 ConnectionFailed error.",
        "details": "## Goal\nEnsure the Vercel deployment of the web app has all required secrets/config for Mastra + Turso (LibSQL) + model provider + external tools so that /api/chat can initialize successfully and stream responses.\n\n## Prerequisites\n- Turso (hosted LibSQL) database is provisioned and credentials are available (LIBSQL_URL + LIBSQL_AUTH_TOKEN) from Task 12.\n\n## Variables to configure (Vercel Project → Settings → Environment Variables)\nConfigure these **for the feature/mastra-migration branch deployment context** (Preview environment at minimum; Production if applicable) and ensure they match what the code expects.\n\n### 1) LibSQL / Turso\n- `LIBSQL_URL` = `libsql://...` (from Turso)\n- `LIBSQL_AUTH_TOKEN` = Turso auth token (from Turso)\n\nNotes:\n- Confirm there are no stray/legacy variables (e.g., old SQLite file path overrides) that would override these.\n- Ensure values do not contain surrounding quotes.\n\n### 2) Model provider selection\nSet these to match the Mastra model routing implemented in the codebase.\n- `DEXTER_MODEL_PROVIDER` = e.g., `openai` (or the provider your deployment is meant to use)\n- `DEXTER_MODEL` = e.g., the model name expected by your provider selection (as used by the app)\n\n(If the code expects a single combined model string instead, ensure these two env vars align with the existing configuration conventions. The objective is that the deployed /api/chat can resolve a valid model identifier without throwing during initialization.)\n\n### 3) Provider API keys\n- `OPENAI_API_KEY` = OpenAI key (required if using OpenAI for chat and/or embeddings)\n\n### 4) Tooling / data provider keys\n- `FINANCIAL_DATASETS_API_KEY` = key for financial datasets provider\n- `EXASEARCH_API_KEY` **or** `TAVILY_API_KEY` = search tool provider key (set the one the code is currently wired to use)\n\nNotes:\n- If the code supports both Exa and Tavily but prioritizes one, set only the intended one or set both (prefer setting only what is necessary to reduce ambiguity).\n\n## Branch / environment scoping\n1. In Vercel, confirm the Git branch `feature/mastra-migration` is connected and producing Preview deployments.\n2. Add variables under the correct environment(s):\n   - **Preview**: required for branch deployments.\n   - **Production**: only if you intend to promote/merge and want continuity.\n3. If using Vercel “Environment Variable Overrides” by branch, ensure these variables are included in that scope.\n\n## Redeploy procedure\n1. Trigger a redeploy for the latest commit on `feature/mastra-migration`:\n   - Use Vercel UI: Deployments → select latest for the branch → “Redeploy”, or push an empty commit to trigger a build.\n2. Confirm the new deployment is using the updated env vars:\n   - Vercel UI → Deployment → “Build Logs” and “Runtime Logs” (ensure there are no startup-time missing env var errors).\n\n## Debugging guidance (if still 500)\nIf /api/chat still returns 500, use Vercel runtime logs to pinpoint which initialization step fails:\n- Missing env var error (common): add/rename the variable to match code.\n- Turso connection failure: validate LIBSQL_URL/token, and ensure outbound networking is allowed (Turso is public; usually fine).\n- Model provider auth error: confirm OPENAI_API_KEY present and correct, and DEXTER_MODEL_PROVIDER/DEXTER_MODEL resolve to a valid model.\n- Search/financial tool failure should not crash initialization; if it does, consider making tool init lazy or tolerant, but keep this task focused on env configuration + redeploy verification.\n\n## Security\n- Do not commit secrets to the repo.\n- Verify no secrets are printed in logs; redact if any code logs env vars.",
        "testStrategy": "## 1) Confirm environment variables are set correctly\n- In Vercel Project → Settings → Environment Variables:\n  - Verify `LIBSQL_URL`, `LIBSQL_AUTH_TOKEN`, `OPENAI_API_KEY`, `FINANCIAL_DATASETS_API_KEY`, and `EXASEARCH_API_KEY` (or `TAVILY_API_KEY`) exist.\n  - Verify `DEXTER_MODEL_PROVIDER` and `DEXTER_MODEL` exist.\n  - Ensure each is enabled for the **Preview** environment (and for the correct branch if branch scoping is used).\n\n## 2) Redeploy and validate build/runtime\n- Trigger a redeploy of the `feature/mastra-migration` deployment.\n- Acceptance: Build succeeds; runtime logs do not show missing env var errors or connection initialization failures.\n\n## 3) Validate /api/chat returns 200 and streams\nRun against the newly deployed Preview URL.\n\n### Streaming check via curl\n- Execute (adjust URL/path if needed):\n  - `curl -N -i -X POST \"https://<preview-url>/api/chat\" -H \"Content-Type: application/json\" -d '{\"messages\":[{\"role\":\"user\",\"content\":\"Say hello in one sentence.\"}]}'`\n- Acceptance:\n  - HTTP status is **200** (not 500).\n  - Response begins streaming (output arrives incrementally; connection remains open briefly).\n  - The previous `ConnectionFailed` error is not present.\n\n### Browser/app check\n- Open the deployed web UI and send a message.\n- Acceptance:\n  - The assistant response visibly streams (token-by-token or chunk-by-chunk).\n  - No client-side error toast due to 500.\n\n## 4) Regression spot-check: memory persistence path\n(Optional but recommended): Send two messages in the same session to ensure the request does not crash when accessing memory storage.\n- Acceptance: second message succeeds; Vercel logs show no LibSQL connection errors.",
        "status": "pending",
        "dependencies": [
          12
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Confirm Vercel project/branch deployment context for feature/mastra-migration",
            "description": "Verify the Vercel project is connected to the Git repo and that the feature/mastra-migration branch produces Preview deployments with the correct environment-variable scope.",
            "dependencies": [],
            "details": "In Vercel: Project → Settings → Git, confirm the repo is connected and the branch feature/mastra-migration is building Preview deployments. Identify whether you are using standard Preview/Production scopes or branch-based Environment Variable Overrides. Note the latest deployment URL for the branch to use for validation later.",
            "status": "pending",
            "testStrategy": "Check Vercel Deployments list shows recent Preview deployments for feature/mastra-migration and you can open the preview URL."
          },
          {
            "id": 2,
            "title": "Add/verify LibSQL (Turso) env vars with correct scoping and no overrides",
            "description": "Configure LIBSQL_URL and LIBSQL_AUTH_TOKEN for the branch deployment context and ensure no legacy variables override Mastra/Turso configuration.",
            "dependencies": [
              1
            ],
            "details": "Vercel Project → Settings → Environment Variables: add/update LIBSQL_URL and LIBSQL_AUTH_TOKEN for Preview (and Production if intended). Ensure values are raw (no surrounding quotes) and match the Turso credentials from Task 12. Audit for stray/legacy DB vars (e.g., file-based sqlite path, older DB URL vars, or conflicting overrides) and remove/disable them if they could take precedence in runtime config.",
            "status": "pending",
            "testStrategy": "After saving env vars, confirm in Vercel UI they appear under the intended environment scope (Preview/branch override) and values are not quoted."
          },
          {
            "id": 3,
            "title": "Configure model routing env vars and provider API key for Mastra",
            "description": "Set DEXTER_MODEL_PROVIDER/DEXTER_MODEL to values expected by the code and add the provider API key needed for chat/embeddings.",
            "dependencies": [
              2
            ],
            "details": "In Vercel environment variables for the same scope: set DEXTER_MODEL_PROVIDER (e.g., openai) and DEXTER_MODEL (the model identifier your Mastra routing expects). Add OPENAI_API_KEY if using OpenAI (and ensure no conflicting provider key vars cause ambiguity). Double-check naming matches exactly what the code reads (case-sensitive) so /api/chat initialization can resolve a valid provider + model.",
            "status": "pending",
            "testStrategy": "Redeploy later and verify runtime logs do not show missing/invalid provider/model env errors; optionally test a minimal /api/chat call to confirm it reaches model invocation."
          },
          {
            "id": 4,
            "title": "Configure external tool provider keys (financial datasets + search) with minimal ambiguity",
            "description": "Add required API keys for external tools used by the agent and ensure only the intended search provider key(s) are set.",
            "dependencies": [
              3
            ],
            "details": "In Vercel env vars for the same scope: set FINANCIAL_DATASETS_API_KEY. For search, set EXASEARCH_API_KEY or TAVILY_API_KEY based on what the code is currently wired to use; prefer setting only the one intended to avoid ambiguous priority. Re-check that none of these secrets are echoed in logs by default (no code change here; just be mindful when reviewing logs).",
            "status": "pending",
            "testStrategy": "Post-redeploy, confirm /api/chat no longer fails during tool initialization and runtime logs do not show missing key errors for the configured tools."
          },
          {
            "id": 5,
            "title": "Redeploy feature/mastra-migration and validate /api/chat returns 200 with streaming tokens",
            "description": "Trigger a new deployment using the updated environment variables and confirm the API endpoint behavior is fixed (no 500 ConnectionFailed).",
            "dependencies": [
              4
            ],
            "details": "Trigger redeploy via Vercel Deployments → select latest for feature/mastra-migration → Redeploy (or push an empty commit). After deploy completes, validate: (1) Vercel Build Logs show no env-related failures, (2) Runtime Logs show successful initialization (no ConnectionFailed), (3) Call /api/chat from the app UI or via curl and confirm HTTP 200 and streaming response (SSE/chunked tokens) rather than a 500. If it still fails, use runtime logs to pinpoint which env var or connectivity step is failing and iterate on env var corrections (without committing secrets).",
            "status": "pending",
            "testStrategy": "Integration test: invoke /api/chat against the Preview URL with a simple prompt; assert status=200 and response streams chunks/tokens; verify Vercel runtime logs are free of ConnectionFailed and missing-env errors."
          }
        ]
      },
      {
        "id": 14,
        "title": "Validate Mastra Studio runs locally with AlphaSentry agent and observability features",
        "description": "Run Mastra Studio locally and verify the AlphaSentry agent is discoverable and usable end-to-end (chat, tools, memory/threads, traces). Capture and document any configuration tweaks or issues required to make Studio reliably work for local development.",
        "details": "## Goal\nConfirm that Mastra Studio can be used as the primary local developer surface to interact with the AlphaSentry agent and inspect runtime behavior (tools, memory threads, traces).\n\n## Prerequisites\n- Local environment can run the project with Bun.\n- Task 9 memory wiring is complete and enabled for the agent.\n\n## Steps\n1) **Confirm Studio command and directory layout**\n- Verify `bun run studio` exists in `package.json` and calls:\n  - `npx mastra dev --dir src/mastra`\n- Ensure `src/mastra` exports/declares the AlphaSentry agent in a way Studio can discover (e.g., via `src/mastra/index.ts` exporting/creating the Mastra app instance and registering agents).\n\n2) **Run Studio locally**\n- From repo root:\n  - `bun run studio`\n- Confirm expected output includes the server URL and port.\n- Open: `http://localhost:4111`\n\n3) **Verify AlphaSentry agent appears in Studio**\n- In Studio UI, locate agents list/catalog.\n- Confirm `alpha-sentry` (or the expected agent id/name) is present.\n- If it does not appear, inspect `src/mastra/index.ts` (or the Mastra app entrypoint) for:\n  - agent registration\n  - correct agent id/name\n  - correct exports for Studio discovery\n\n4) **Verify chat works end-to-end**\n- Start a new conversation with AlphaSentry in Studio.\n- Send a simple prompt (e.g., “Hello—what can you do?”), then a tool-likely prompt (e.g., “What is the current price of AAPL?”).\n- Confirm:\n  - Response renders in Studio\n  - No runtime errors in terminal logs\n  - Tool call is executed when expected\n\n5) **Verify tools are listed and individually testable**\n- Navigate to the tools section in Studio for AlphaSentry.\n- Confirm all leaf tools from the Mastra tool registry appear (at least representative tools across finance/search/browser/skills).\n- For at least 3 tools (one finance, one search, one browser/utility):\n  - Run the tool directly in Studio using valid inputs\n  - Confirm output returns successfully and matches the tool’s expected schema\n- If a tool fails, capture:\n  - tool id\n  - input payload\n  - error stack/response\n  - suspected missing env var (e.g., `FINANCIAL_DATASETS_API_KEY`, `EXASEARCH_API_KEY`/`TAVILY_API_KEY`)\n\n6) **Verify memory + threads are visible and working**\n- In Studio, find the memory/threads view.\n- Confirm:\n  - a thread is created/selected when you chat\n  - thread id/resource id is visible (or can be inferred from UI)\n  - prior messages appear when revisiting the same thread\n- Run a 2-turn check:\n  1) Ask: “Remember that my favorite ticker is MSFT.”\n  2) Ask: “What’s my favorite ticker?”\n  Confirm the agent answers correctly within the same thread.\n- Restart Studio (`CTRL+C`, re-run `bun run studio`) and attempt to reload the same thread (if Studio supports selecting existing threads). Confirm persistence is working as expected.\n\n7) **Verify traces show tool call details**\n- Open the traces/run view for the last chat.\n- Confirm traces include:\n  - tool name/id\n  - tool input arguments\n  - tool output (or a preview)\n  - timing/step boundaries\n- Validate that trace data is sufficiently detailed to debug failures (inputs/outputs are present, not just “tool called”).\n\n8) **Document issues + configuration tweaks**\nCreate/update a local developer doc (prefer `docs/mastra-studio.md` or `README.md` section) with:\n- How to run Studio (`bun run studio`, URL, port)\n- Required environment variables for common tools + memory\n- Any required files/dirs (e.g., `.dexter/` for local LibSQL)\n- Known issues and fixes (examples):\n  - agent not appearing in Studio due to missing export/registration\n  - port conflicts (how to change port)\n  - Bun vs Node quirks when running `npx mastra dev`\n  - missing env vars causing tool failures\n- Add a short troubleshooting checklist:\n  - “Agent not listed” → verify `src/mastra` entrypoint and agent registration\n  - “Tools missing” → verify Mastra tool registry wiring\n  - “Memory not persisting” → verify LibSQL path/permissions and thread/resource id wiring\n\n## Output artifacts\n- A short doc with the above runbook and troubleshooting.\n- If you needed code/config changes to make Studio work reliably, include them in the PR with a brief rationale in the doc (keep changes minimal and Studio-focused).",
        "testStrategy": "## Manual acceptance test (required)\n1) Start Studio:\n- `bun run studio`\n- Open `http://localhost:4111`\n\n2) Agent discovery:\n- Confirm AlphaSentry appears in the Agents list.\n\n3) Chat:\n- Send two prompts:\n  - “Hello—summarize your capabilities.”\n  - “What is the current price of AAPL?”\n- Confirm a successful response in both cases.\n\n4) Tools listing + direct execution:\n- In Tools view, confirm tools are listed.\n- Execute at least 3 tools individually (finance, search, utility/browser).\n- Confirm outputs are returned and no unhandled exceptions occur.\n\n5) Memory/threads:\n- In a single thread, run:\n  - “Remember that my favorite ticker is MSFT.”\n  - “What’s my favorite ticker?”\n- Confirm MSFT is recalled.\n- Restart Studio and verify thread persistence/visibility behavior matches expectations (either the same thread is selectable and retains history, or document limitations if Studio does not expose thread selection).\n\n6) Traces:\n- Open the trace for the AAPL prompt.\n- Confirm trace contains tool call input + output details.\n\n## Documentation acceptance test\n- Verify a doc exists (e.g., `docs/mastra-studio.md`) and includes:\n  - command to run Studio\n  - required env vars\n  - troubleshooting/known issues\n  - any config tweaks made and why\n\n## Regression checks (quick)\n- `bun run typecheck` passes.\n- Re-running `bun run studio` after a clean restart produces the same successful behavior.",
        "status": "pending",
        "dependencies": [
          9
        ],
        "priority": "medium",
        "subtasks": []
      }
    ],
    "metadata": {
      "version": "1.0.0",
      "lastModified": "2026-02-11T02:11:05.784Z",
      "taskCount": 11,
      "completedCount": 10,
      "tags": [
        "master"
      ],
      "created": "2026-02-12T01:08:26.454Z",
      "description": "Tasks for master context",
      "updated": "2026-02-12T01:12:13.698Z"
    }
  }
}